{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LRW-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRiwd1BLbfoo"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hb5ND5-c7TV"
      },
      "source": [
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.models import Sequential,model_from_yaml\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, LSTM, GRU\n",
        "from tensorflow.keras.layers import TimeDistributed, Conv3D,MaxPooling3D, ZeroPadding3D\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import mediapipe as mp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxjTU3HogunQ"
      },
      "source": [
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_face_mesh = mp.solutions.face_mesh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkF9Kuoog_5f"
      },
      "source": [
        "def preprocessing(cap):\n",
        " \n",
        "    euclid_dist = np.empty(shape=(25,40))\n",
        "    terminate_flag,count,inner_count = 0,0,0\n",
        "\n",
        "    #randomizing the 25 frames.\n",
        "    rand_list = [0,1,2,3,25,26,27,28]\n",
        "    key = random.choice(rand_list)\n",
        "    if key>24:\n",
        "        no_frame = list(range(key - 25,key))\n",
        "    else:\n",
        "        no_frame = list(range(key,key+25))\n",
        "\n",
        "    lips = [0, 13, 14, 17, 37, 39, 40, 61, 78, 80, 81, 82, 84, 87, 88, 91, 95, 146, 178, 181, 185, 191, 267, 269, 270, 291, 308, 310, 311, 312, 314, 317, 318, 321, 324, 375, 402, 405, 409, 415]\n",
        "\n",
        "    while(cap.isOpened()):\n",
        "        ret, frame = cap.read()\n",
        "        if ret == True:\n",
        "            if count in no_frame:\n",
        "                mean_x,mean_y = 0,0\n",
        "                with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5) as face_mesh:\n",
        "                  # Convert the BGR image to RGB before processing.\n",
        "                  results = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "                  # Print and draw face mesh landmarks on the image.\n",
        "                  if results.multi_face_landmarks:\n",
        "                      for n in lips:\n",
        "                          x_mouth = results.multi_face_landmarks[0].landmark[n].x\n",
        "                          y_mouth = results.multi_face_landmarks[0].landmark[n].y\n",
        "\n",
        "                          shape = frame.shape \n",
        "                          relative_x = int(x_mouth * shape[1])\n",
        "                          relative_y = int(y_mouth * shape[0])\n",
        "                          mean_x = mean_x + relative_x\n",
        "                          mean_y = mean_y + relative_y\n",
        "                      mean_x = mean_x/40\n",
        "                      mean_y = mean_y/40\n",
        "                      int_count = 0\n",
        "                      for n in lips:\n",
        "                          x_mouth = results.multi_face_landmarks[0].landmark[n].x\n",
        "                          y_mouth = results.multi_face_landmarks[0].landmark[n].y\n",
        "\n",
        "                          shape = frame.shape \n",
        "                          relative_x = int(x_mouth * shape[1])\n",
        "                          relative_y = int(y_mouth * shape[0])\n",
        "                          euclid_dist[inner_count,int_count] = math.sqrt(math.pow((mean_x-relative_x),2)+math.pow((mean_y-relative_y),2))\n",
        "                          int_count += 1\n",
        "                inner_count +=1\n",
        "            count+=1\n",
        "        else:\n",
        "            break  \n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    \n",
        "    return euclid_dist,1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plAAkhcgj3nw"
      },
      "source": [
        "def data_generator(word,n_train,n_val,n_test,class_dict):\n",
        "    #TRAINING SET \n",
        "    first_flag,actual_count = 0,0\n",
        "    for vid in range(n_train):\n",
        "        if vid<9:\n",
        "            cap = cv2.VideoCapture('/content/drive/MyDrive/Project/LRW/project_dataset/{0}/train/{1}_0000{2}.mp4'.format(word,word,str(vid+1)))\n",
        "        elif vid>=9 and vid<99:\n",
        "            cap = cv2.VideoCapture('/content/drive/MyDrive/Project/LRW/project_dataset/{0}/train/{1}_000{2}.mp4'.format(word,word,str(vid+1)))\n",
        "        elif vid>=99 and vid<999:\n",
        "            cap = cv2.VideoCapture('/content/drive/MyDrive/Project/LRW/project_dataset/{0}/train/{1}_00{2}.mp4'.format(word,word,str(vid+1)))\n",
        "        elif vid==999:\n",
        "            cap = cv2.VideoCapture('/content/drive/MyDrive/Project/LRW/project_dataset/{0}/train/{1}_01000.mp4'.format(word,word))\n",
        "        \n",
        "        #ONLY FOR FIRST VIDEO\n",
        "        temp,bool_flag = preprocessing(cap)  \n",
        "        if bool_flag == 1 and first_flag == 0:\n",
        "            X_train = temp\n",
        "            first_flag = 1\n",
        "            actual_count += 1\n",
        "        \n",
        "        #FOR THE REST OF THE VIDEOS\n",
        "        elif bool_flag == 1:\n",
        "            X_train = np.append(X_train,temp,axis=0)\n",
        "            actual_count += 1\n",
        "\n",
        "        print(\"{}/{}\".format(actual_count,350))\n",
        "\n",
        "    X_train = X_train.reshape(actual_count,25,40).astype('float32')\n",
        "\n",
        "    y_train = [None]*actual_count \n",
        "    for i in range(actual_count):\n",
        "        y_train[i] = class_dict[word]\n",
        "    \n",
        "\n",
        "    #VALIDATION SET\n",
        "    first_flag,actual_count = 0,0\n",
        "    for vid in range(n_val):\n",
        "        cap = cv2.VideoCapture('/content/drive/MyDrive/Project/LRW/project_dataset/{0}/train/{1}_00{2}.mp4'.format(word,word,str(vid+1+750)))\n",
        "            \n",
        "        temp,bool_flag = preprocessing(cap)  \n",
        "        \n",
        "        #ONLY FOR FIRST VIDEO\n",
        "        if bool_flag == 1 and first_flag == 0:\n",
        "            X_val = temp\n",
        "            first_flag = 1\n",
        "            actual_count += 1\n",
        "          \n",
        "        #FOR THE REST OF THE VIDEOS\n",
        "        elif bool_flag == 1:\n",
        "            X_val = np.append(X_val,temp,axis=0)\n",
        "            actual_count += 1\n",
        "        \n",
        "        print(\"{}/{}\".format(actual_count,50))\n",
        "\n",
        "    X_val = X_val.reshape(actual_count,25,40).astype('float32')\n",
        "  \n",
        "    y_val = [None]*actual_count \n",
        "    for i in range(actual_count):\n",
        "        y_val[i] = class_dict[word]\n",
        "\n",
        "\n",
        "    #TEST SET\n",
        "    first_flag,actual_count = 0,0\n",
        "    for vid in range(n_test):\n",
        "        if vid<9:\n",
        "            cap = cv2.VideoCapture('/content/drive/MyDrive/Project/LRW/project_dataset/{0}/test/{1}_0000{2}.mp4'.format(word,word,str(vid+1)))\n",
        "        elif vid>=9 and vid<50:\n",
        "            cap = cv2.VideoCapture('/content/drive/MyDrive/Project/LRW/project_dataset/{0}/test/{1}_000{2}.mp4'.format(word,word,str(vid+1)))\n",
        "\n",
        "        temp,bool_flag = preprocessing(cap)  \n",
        "        \n",
        "        if bool_flag == 1 and first_flag == 0:\n",
        "            X_test = temp\n",
        "            first_flag = 1\n",
        "            actual_count += 1\n",
        "          \n",
        "        elif bool_flag == 1:\n",
        "            X_test = np.append(X_test,temp,axis=0)\n",
        "            actual_count += 1\n",
        "\n",
        "        print(\"{}/{}\".format(actual_count,50))\n",
        "\n",
        "\n",
        "    X_test = X_test.reshape(actual_count,25,40).astype('float32')\n",
        "  \n",
        "    y_test = [None]*actual_count \n",
        "    for i in range(actual_count):\n",
        "        y_test[i] = class_dict[word]\n",
        "\n",
        "\n",
        "    y_train = np.asarray(y_train)\n",
        "    y_test = np.asarray(y_test)\n",
        "    y_val = np.asarray(y_val)\n",
        "    \n",
        "    return X_train,y_train,X_val,y_val,X_test,y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU2iBRlnoWo0"
      },
      "source": [
        "def create_dataset(class_dict):\n",
        "    first_flag, counter = 0,0\n",
        "    for word in class_dict.keys():\n",
        "        trainX,trainY,valX,valY,testX,testY = data_generator(word,350,50,50,class_dict)\n",
        "\n",
        "        if first_flag == 0:\n",
        "            X_train = trainX\n",
        "            X_test = testX\n",
        "            X_val = valX\n",
        "            y_train = trainY\n",
        "            y_test = testY\n",
        "            y_val = valY\n",
        "            first_flag = 1\n",
        "        else:\n",
        "            X_train = np.append(X_train,trainX,axis=0)\n",
        "            X_test = np.append(X_test,testX,axis=0)\n",
        "            X_val = np.append(X_val,valX,axis=0)\n",
        "            y_train = np.append(y_train,trainY,axis=0)\n",
        "            y_test = np.append(y_test,testY,axis=0)\n",
        "            y_val = np.append(y_val,valY,axis=0)\n",
        "\n",
        "        counter+=1        \n",
        "        print(\"Words processed:{}/{}\".format(counter,4))\n",
        "\n",
        "    y_train = utils.to_categorical(y_train)\n",
        "    y_test = utils.to_categorical(y_test)\n",
        "    y_val = utils.to_categorical(y_val)\n",
        "\n",
        "    return X_train,X_test,X_val,y_val,y_train,y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5-l2eARordh"
      },
      "source": [
        "class_dict = {'ABUSE':1,'BLACK':2,'CRIME':3,'EXACTLY':4}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Lat-r3NouAi"
      },
      "source": [
        "X_train,X_test,X_val,y_val,y_train,y_test = create_dataset(class_dict) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2tnze38cJ-F"
      },
      "source": [
        "path='/content/drive/MyDrive/Project/LRW/main_file/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVw4CenghQom"
      },
      "source": [
        "np.save(path+'X_train3.npy',X_train)\n",
        "np.save(path+'X_test3.npy',X_test)\n",
        "np.save(path+'X_val3.npy',X_val)\n",
        "np.save(path+'y_train3.npy',y_train)\n",
        "np.save(path+'y_test3.npy',y_test)\n",
        "np.save(path+'y_val3.npy',y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjIur2dUrgm5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}